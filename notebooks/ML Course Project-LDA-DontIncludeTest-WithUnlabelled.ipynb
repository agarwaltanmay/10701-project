{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Course Project\n",
    "## Identifying User Stance On Social Media via Semi-Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "#### Midsem Pipeline - \n",
    "\n",
    " - **Read Data**: Read text files to load all the words. \n",
    " - **Clean Data**: Remove stop-words, everything lowercase, dehashify hashtags.\n",
    " - **Format Data**: Create data in a format required by each baseline method. \n",
    " - **Baseline Approaches**: LSA, pLSA, Para2Vec, LDA Topic Modelling. The goal of these approaches is to create a \"FIXED SIZE\" and \"HIGH LEVEL\" feature representation for variable length tweets. These representations leverage our unlabelled data. \n",
    " - **Training**: Some Supervised Learning on the learned representation using the given labels. \n",
    " - **Evaluation**: Compare the different methods mentioned above on different datasets. \n",
    "\n",
    "#### Endsem Approaches - \n",
    " - LDA2Vec - https://www.datacamp.com/community/tutorials/lda2vec-topic-model\n",
    " - Gaussian LDA - https://rajarshd.github.io/papers/acl2015.pdf\n",
    " - Word Embeddings Informed Topic Models - http://proceedings.mlr.press/v77/zhao17a/zhao17a.pdf\n",
    " \n",
    "#### Reference\n",
    " - https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_LABELLED_DATA_TRUMP = \"../semeval2016-task6-domaincorpus/data-all-annotations/testdata-taskB-all-annotations.txt\"\n",
    "PATH_UNLABELLED_DATA_TRUMP = \"./../semeval2016-task6-domaincorpus/downloaded_Donald_Trump.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "# # Run in python console\n",
    "# import nltk; nltk.download('stopwords')\n",
    "\n",
    "# # Run in terminal or command prompt\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim\n",
    "# !pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LsiModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['via'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Sem-Eval Task A Data (Labelled)\n",
    "\n",
    "Interactive Visualization - http://www.saifmohammad.com/WebPages/StanceDataset.htm\n",
    "\n",
    "Targets - \n",
    " - Hilary Clinton\n",
    " - Atheism\n",
    " - Climate Change\n",
    " - Donald Trump\n",
    " - Feminism\n",
    " - Abortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle('X_train.pkl')\n",
    "X_test = pd.read_pickle('X_test.pkl')\n",
    "y_train = pd.read_pickle('y_train.pkl')\n",
    "y_test = pd.read_pickle('y_test.pkl')\n",
    "\n",
    "data_labelled_train = pd.concat([X_train, y_train], ignore_index=True, axis=1)\n",
    "data_labelled_train.columns = ['Tweet', 'Stance']\n",
    "data_labelled_test = pd.concat([X_test, y_test], ignore_index=True, axis=1)\n",
    "data_labelled_test.columns = ['Tweet', 'Stance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(sent):\n",
    "    sent = str(sent)\n",
    "    \n",
    "    # Remove new line characters\n",
    "    sent = re.sub('\\s+', ' ', sent)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    sent = re.sub(\"\\'\", \"\", sent)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    sent = re.sub(\"\\\"\", \"\", sent)\n",
    "\n",
    "    # Remove hashtags\n",
    "    sent = re.sub(\"\\#\", \"\", sent)\n",
    "\n",
    "    # Remove http:// links\n",
    "    sent = re.sub('http:\\/\\/.*','', sent)\n",
    "\n",
    "    # Remove https:// links\n",
    "    sent = re.sub('https:\\/\\/.*','', sent)\n",
    "        \n",
    "    return sent\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet     211\n",
       "Stance    211\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labelled_train.where(data_labelled_train.Stance == 'AGAINST').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet     209\n",
       "Stance    209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labelled_train.where(data_labelled_train.Stance == 'NONE').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet     207\n",
       "Stance    207\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labelled_train.where(data_labelled_train.Stance == 'FAVOR').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet     88\n",
       "Stance    88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labelled_test.where(data_labelled_test.Stance == 'AGAINST').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet     90\n",
       "Stance    90\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labelled_test.where(data_labelled_test.Stance == 'NONE').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet     92\n",
       "Stance    92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labelled_test.where(data_labelled_test.Stance == 'FAVOR').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Sem-Eval Task B Data (Unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unlabelled = pd.read_csv(PATH_UNLABELLED_DATA_TRUMP, sep='\\t', lineterminator='\\n', encoding ='latin1', names = [\"ID\", \"Tweet\"])\n",
    "data_unlabelled = data_unlabelled.where(data_unlabelled.Tweet != 'Not Available')\n",
    "data_unlabelled.dropna(how='any', inplace=True)\n",
    "data_unlabelled['Tweet'] = data_unlabelled['Tweet'].apply(lambda x: x[1:])\n",
    "data_unlabelled['Tweet'] = data_unlabelled['Tweet'].apply(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "combined_data = pd.concat([data_labelled_test, data_labelled_train, data_unlabelled], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        53616\n",
       "Stance      897\n",
       "Tweet     54513\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>I nominate Donald Trump for the new ambassador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>Jeb Bush Why Dont U Stand Up For Yr Mexican Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>RT @Tone_Rowdy: How can this country move on f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AGAINST</td>\n",
       "      <td>@marcorubio . Adios for your comments about @r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>One of the key problems today is that politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>@ericbolling :). Sorry for the kidding but had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>25% of Mexico has INVADED AMERICA - &amp; CONTINUE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>@docweiser01 @ericbolling @JonathanHoenig @Mic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Liberals are winning the battle of the mind by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>FAVOR</td>\n",
       "      <td>@realDonaldTrump they may be dumping you now, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Stance                                              Tweet\n",
       "0 NaN  AGAINST  I nominate Donald Trump for the new ambassador...\n",
       "1 NaN  AGAINST  Jeb Bush Why Dont U Stand Up For Yr Mexican Fa...\n",
       "2 NaN     NONE  RT @Tone_Rowdy: How can this country move on f...\n",
       "3 NaN  AGAINST  @marcorubio . Adios for your comments about @r...\n",
       "4 NaN    FAVOR  One of the key problems today is that politics...\n",
       "5 NaN     NONE  @ericbolling :). Sorry for the kidding but had...\n",
       "6 NaN    FAVOR  25% of Mexico has INVADED AMERICA - & CONTINUE...\n",
       "7 NaN     NONE  @docweiser01 @ericbolling @JonathanHoenig @Mic...\n",
       "8 NaN     NONE  Liberals are winning the battle of the mind by...\n",
       "9 NaN    FAVOR  @realDonaldTrump they may be dumping you now, ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_data['Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I nominate Donald Trump for the new ambassador to Mexico. Mexico Tacos SemST']\n"
     ]
    }
   ],
   "source": [
    "data = df.values.tolist()\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences To Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nominate',\n",
      "  'donald',\n",
      "  'trump',\n",
      "  'for',\n",
      "  'the',\n",
      "  'new',\n",
      "  'ambassador',\n",
      "  'to',\n",
      "  'mexico',\n",
      "  'mexico',\n",
      "  'tacos',\n",
      "  'semst']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "pprint(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bi-Grams Tri-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nominate', 'donald', 'trump', 'for', 'the', 'new', 'ambassador', 'to', 'mexico', 'mexico', 'tacos', 'semst']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stop Words and Lemmatize\n",
    "\n",
    "WE NEED PRONOUNS FOR STANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PRON']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['nominate', 'donald', 'trump', 'new', 'ambassador', 'mexico', 'mexico', 'taco', 'semst']]\n",
      "54513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV', 'PRON'])\n",
    "\n",
    "print(data_lemmatized[:1]), print(len(data_lemmatized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('ambassador', 1),\n",
       "  ('donald', 1),\n",
       "  ('mexico', 2),\n",
       "  ('new', 1),\n",
       "  ('nominate', 1),\n",
       "  ('semst', 1),\n",
       "  ('taco', 1),\n",
       "  ('trump', 1)]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31242"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA-Mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# !unzip mallet-2.0.8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet('./mallet-2.0.8/bin/mallet', corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = corpus[270:]\n",
    "train_data_lemmatized = data_lemmatized[270:]\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=train_corpus, texts=train_data_lemmatized, start=2, limit=51, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=51; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = x[np.argmax(coherence_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_path = './mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=train_corpus, num_topics=num_topics, id2word=id2word)\n",
    "ldamallet = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "# Save model to disk.\n",
    "temp_file = datapath(\"lda-mallet-model-only-labelled-\"+str(num_topics)+\"dont-include-test\")\n",
    "ldamallet.save(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "\n",
    "temp_file = datapath(\"lda-mallet-model-only-labelled-\"+str(num_topics)+\"dont-include-test\")\n",
    "# Load a potentially pretrained model from disk.\n",
    "ldamallet = gensim.models.ldamodel.LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Quality Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=train_data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset for Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_corpus = corpus[:897]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_feats = []\n",
    "\n",
    "for i in range(len(labelled_corpus)):\n",
    "    representation = ldamallet.get_document_topics(labelled_corpus[i])\n",
    "    count = 0\n",
    "    feat = []\n",
    "    for i in range(num_topics):\n",
    "        if i in list(map((lambda x: x[0]), representation)):\n",
    "            feat.append(representation[count][1])\n",
    "            count = count + 1\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    mallet_feats.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANCES = ['AGAINST', 'FAVOR', 'NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(label):\n",
    "    if label == 'AGAINST':\n",
    "        return 0\n",
    "    elif label == 'FAVOR':\n",
    "        return 1\n",
    "    elif label == 'NONE':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_stance = pd.concat([data_labelled_test['Stance'], data_labelled_train['Stance']]) \n",
    "labelled_stance = labelled_stance.apply(transform_labels)\n",
    "labelled_stance = labelled_stance.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mallet_feats[0]), len(mallet_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "import argparse\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Train Test Split\n",
    "X_train = mallet_feats[270:]\n",
    "X_test = mallet_feats[:270]\n",
    "y_train = labelled_stance[270:]\n",
    "y_test = labelled_stance[:270]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # GRID SEARCH\n",
    "    parameters = {'n_estimators':range(100,600,100), 'max_depth':range(1,20,5)}\n",
    "    rlf = RandomForestClassifier(random_state=0)\n",
    "    rlf = GridSearchCV(rlf, parameters, cv=5)\n",
    "    rlf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rlf.predict(X_test)\n",
    "\n",
    "    rf_cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(y_test, y_pred, classes=STANCES,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "    rf_cv = cross_val_score(rlf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    report = {}\n",
    "    report[\"RF_cross_val_score\"] = rf_cv.tolist()\n",
    "    report[\"RF_mean_acc\"] = rf_cv.mean()\n",
    "    report[\"RF_std_acc\"] = rf_cv.std()*2\n",
    "    report[\"RF_best_estimator\"] = rlf.best_estimator_\n",
    "    \n",
    "    report[\"RF_CM\"] = rf_cm.tolist()\n",
    "    \n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    report[\"RF_F1_SCORE\"] = f1_macro\n",
    "\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMClassifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    parameters = {'kernel':['linear','rbf','poly'], 'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    \n",
    "    clf = svm.SVC(gamma='auto')\n",
    "    clf = GridSearchCV(clf, parameters, cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    clf_cv = cross_val_score(clf, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    report = {}\n",
    "    report[\"SVM_cross_val_score\"] = clf_cv.tolist()\n",
    "    report[\"SVM_mean_acc\"] = clf_cv.mean()\n",
    "    report[\"SVM_std_acc\"] = clf_cv.std()*2\n",
    "    report[\"SVM_best_estimator\"] = clf.best_estimator_\n",
    "\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    clf_cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(y_test, y_pred, classes=STANCES,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "    report[\"SVM_CM\"] = clf_cm.tolist()\n",
    "    \n",
    "    f1_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    report[\"SVM_F1_SCORE\"] = f1_macro\n",
    "\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_report = RandomForest(X_train, X_test, y_train, y_test)\n",
    "print(mallet_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mallet_report = SVMClassifier(X_train, X_test, y_train, y_test)\n",
    "print(mallet_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
